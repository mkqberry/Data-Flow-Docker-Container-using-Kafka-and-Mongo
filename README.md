# Data-Flow-Docker-Container-using-Kafka-and-Mongo
It provide data flow using Kafka and insert to MongoDB. And also creates a topic and kafka environment with 1 zookeper and 1 broker.

- You should execute command -d"docker compose up" when you're within repo directory. (-d makes it run in the background)
- For the data sending and creating Kafka Producer, you should run "producer.py" file.
- You should run "consumer.py" for inserting data to DataBase.
